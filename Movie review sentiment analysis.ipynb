{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model, configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "CONFIG_PATH = Path('./movie-review-sentiment-analysis_ag_news_wiki.json')  # could also be configuration dictionary or string path or `pathlib.Path` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"dataset_reader\": {\r\n",
      "      \"class_name\": \"basic_classification_reader\",\r\n",
      "      \"x\": \"Phrase\",\r\n",
      "      \"y\": \"Sentiment\",\r\n",
      "      \"format\": \"csv\",\r\n",
      "      \"sep\" : \"\\t\",\r\n",
      "      \"data_path\": \"{DOWNLOADS_PATH}/moview_review_sentiment_analysis_ag_news_wiki\",\r\n",
      "      \"train\": \"train.tsv\",\r\n",
      "      \"test\": \"test.tsv\",\r\n",
      "      \"header\": 0,\r\n",
      "      \"names\": [\r\n",
      "        \"Phrase\",\r\n",
      "        \"Sentiment\"\r\n",
      "      ]\r\n",
      "    },\r\n",
      "    \"dataset_iterator\": {\r\n",
      "      \"class_name\": \"basic_classification_iterator\",\r\n",
      "      \"seed\": 42,\r\n",
      "      \"split_seed\": 23,\r\n",
      "      \"field_to_split\": \"train\",\r\n",
      "      \"split_fields\": [\r\n",
      "        \"train\",\r\n",
      "        \"valid\"\r\n",
      "      ],\r\n",
      "      \"split_proportions\": [\r\n",
      "        0.9,\r\n",
      "        0.1\r\n",
      "      ]\r\n",
      "    },\r\n",
      "     \"chainer\": {\r\n",
      "    \"in\": [\r\n",
      "      \"x\"\r\n",
      "    ],\r\n",
      "    \"in_y\": [\r\n",
      "      \"y\"\r\n",
      "    ],\r\n",
      "    \"pipe\": [\r\n",
      "      {\r\n",
      "        \"id\": \"classes_vocab\",\r\n",
      "        \"class_name\": \"simple_vocab\",\r\n",
      "        \"fit_on\": [\r\n",
      "          \"y\"\r\n",
      "        ],\r\n",
      "        \"save_path\": \"{MODEL_PATH}/classes.dict\",\r\n",
      "        \"load_path\": \"{MODEL_PATH}/classes.dict\",\r\n",
      "        \"in\": \"y\",\r\n",
      "        \"out\": \"y_ids\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": [\r\n",
      "          \"x\"\r\n",
      "        ],\r\n",
      "        \"out\": [\r\n",
      "          \"x_lower\"\r\n",
      "        ],\r\n",
      "        \"class_name\": \"str_lower\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": \"x_lower\",\r\n",
      "        \"out\": \"x_tok\",\r\n",
      "        \"id\": \"my_tokenizer\",\r\n",
      "        \"class_name\": \"nltk_tokenizer\",\r\n",
      "        \"tokenizer\": \"wordpunct_tokenize\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": \"x_tok\",\r\n",
      "        \"out\": \"x_emb\",\r\n",
      "        \"id\": \"my_embedder\",\r\n",
      "        \"class_name\": \"fasttext\",\r\n",
      "        \"load_path\": \"{DOWNLOADS_PATH}/embeddings/wiki.en.bin\",\r\n",
      "        \"pad_zero\": true\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": \"y_ids\",\r\n",
      "        \"out\": \"y_onehot\",\r\n",
      "        \"class_name\": \"one_hotter\",\r\n",
      "        \"depth\": \"#classes_vocab.len\",\r\n",
      "        \"single_vector\": true\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": [\r\n",
      "          \"x_emb\"\r\n",
      "        ],\r\n",
      "        \"in_y\": [\r\n",
      "          \"y_onehot\"\r\n",
      "        ],\r\n",
      "        \"out\": [\r\n",
      "          \"y_pred_probas\"\r\n",
      "        ],\r\n",
      "        \"main\": true,\r\n",
      "        \"class_name\": \"keras_classification_model\",\r\n",
      "        \"save_path\": \"{MODEL_PATH}/model\",\r\n",
      "        \"load_path\": \"{MODEL_PATH}/model\",\r\n",
      "        \"embedding_size\": \"#my_embedder.dim\",\r\n",
      "        \"n_classes\": \"#classes_vocab.len\",\r\n",
      "        \"kernel_sizes_cnn\": [\r\n",
      "          3,\r\n",
      "          5,\r\n",
      "          7\r\n",
      "        ],\r\n",
      "        \"filters_cnn\": 256,\r\n",
      "        \"optimizer\": \"Adam\",\r\n",
      "        \"learning_rate\": 0.01,\r\n",
      "        \"learning_rate_decay\": 0.1,\r\n",
      "        \"loss\": \"binary_crossentropy\",\r\n",
      "        \"coef_reg_cnn\": 1e-4,\r\n",
      "        \"coef_reg_den\": 1e-4,\r\n",
      "        \"dropout_rate\": 0.5,\r\n",
      "        \"dense_size\": 100,\r\n",
      "        \"last_layer_activation\": \"softmax\",\r\n",
      "        \"model_name\": \"cnn_model\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": \"y_pred_probas\",\r\n",
      "        \"out\": \"y_pred_ids\",\r\n",
      "        \"class_name\": \"proba2labels\",\r\n",
      "        \"max_proba\": true\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"in\": \"y_pred_ids\",\r\n",
      "        \"out\": \"y_pred_labels\",\r\n",
      "        \"ref\": \"classes_vocab\"\r\n",
      "      }\r\n",
      "    ],\r\n",
      "    \"out\": [\r\n",
      "      \"y_pred_labels\"\r\n",
      "    ]\r\n",
      "  },\r\n",
      "  \"train\": {\r\n",
      "    \"epochs\": 10,\r\n",
      "    \"batch_size\": 64,\r\n",
      "    \"metrics\": [\r\n",
      "      \"accuracy\",\r\n",
      "      \"f1_macro\",\r\n",
      "      {\r\n",
      "        \"name\": \"roc_auc\",\r\n",
      "        \"inputs\": [\"y_onehot\", \"y_pred_probas\"]\r\n",
      "      }\r\n",
      "    ],\r\n",
      "    \"validation_patience\": 5,\r\n",
      "    \"val_every_n_epochs\": 1,\r\n",
      "    \"log_every_n_epochs\": 1,\r\n",
      "    \"show_examples\": false,\r\n",
      "    \"evaluation_targets\": [\r\n",
      "      \"train\",\r\n",
      "      \"valid\",\r\n",
      "      \"test\"\r\n",
      "    ],\r\n",
      "    \"class_name\": \"nn_trainer\"\r\n",
      "  },\r\n",
      "    \"metadata\": {\r\n",
      "      \"variables\": {\r\n",
      "        \"ROOT_PATH\": \"~/.deeppavlov\",\r\n",
      "        \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\r\n",
      "        \"MODELS_PATH\": \"{ROOT_PATH}/models\",\r\n",
      "        \"MODEL_PATH\": \"{MODELS_PATH}/classifiers/moview_review_sentiment_analysis_ag_news_wiki\"\r\n",
      "      },\r\n",
      "      \"requirements\": [\r\n",
      "        \"{DEEPPAVLOV_PATH}/requirements/tf.txt\",\r\n",
      "        \"{DEEPPAVLOV_PATH}/requirements/fasttext.txt\"\r\n",
      "      ],\r\n",
      "      \"download\": [\r\n",
      "        {\r\n",
      "          \"url\": \"http://files.deeppavlov.ai/datasets/ag_news_data.tar.gz\",\r\n",
      "          \"subdir\": \"{DOWNLOADS_PATH}\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin\",\r\n",
      "          \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/classifiers/topic_ag_news_v3.tar.gz\",\r\n",
      "          \"subdir\": \"{MODELS_PATH}/classifiers\"\r\n",
      "        }\r\n",
      "      ]\r\n",
      "    }\r\n",
      "  }"
     ]
    }
   ],
   "source": [
    "! cat {CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-29 13:33:07.872 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/kuptservol/.deeppavlov/models/classifiers/moview_review_sentiment_analysis_ag_news_wiki/classes.dict]\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "[nltk_data] Downloading package punkt to /home/kuptservol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kuptservol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/kuptservol/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/kuptservol/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2020-03-29 13:33:08.600 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/home/kuptservol/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "Using TensorFlow backend.\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/kuptservol/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/deeppavlov/core/models/keras_model.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/deeppavlov/core/models/keras_model.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-29 13:33:21.712 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 273: [initializing `KerasClassificationModel` from saved]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-29 13:33:22.154 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 283: [loading weights from model.h5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kuptservol/work/code/deeppavlov/deeppavlov-venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-29 13:33:22.461 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 134: Model was successfully initialized!\n",
      "Model summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    230656      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    384256      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    537856      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 256)    1024        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 256)    1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 256)    1024        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          76900       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100)          400         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            505         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 5)            20          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 5)            0           batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,233,665\n",
      "Trainable params: 1,231,919\n",
      "Non-trainable params: 1,746\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(CONFIG_PATH, download=False)  # in case of necessity to download some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['I hate it!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('~/.kaggle/data/sentiment-analysis-on-movie-reviews/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleSubmission.csv  test.tsv\ttrain.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_csv_pd = pd.read_csv(data_path/'test.tsv', delimiter='\\t'); test_csv_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = test_csv_pd['Phrase'].apply(lambda x: model([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An intermittently pleasing but mostly routine effort .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv_pd['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['PhraseId'] = test_csv_pd['PhraseId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId\n",
       "0    156061\n",
       "1    156062\n",
       "2    156063\n",
       "3    156064\n",
       "4    156065"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Sentiment'] = answers.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId Sentiment\n",
       "0    156061         3\n",
       "1    156062         3\n",
       "2    156063         2\n",
       "3    156064         3\n",
       "4    156065         3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(data_path/'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 583k/583k [00:04<00:00, 142kB/s]\n",
      "Successfully submitted to Sentiment Analysis on Movie Reviews"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit sentiment-analysis-on-movie-reviews -f {data_path/'submission.csv'} -m \"My submission\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
